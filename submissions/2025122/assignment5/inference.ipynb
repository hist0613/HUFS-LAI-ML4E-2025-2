{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Model Inference\n",
    "## Using the Trained Text Classification Model for Predictions\n",
    "\n",
    "This notebook demonstrates how to load and use the trained model to make predictions on new arXiv paper abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SentenceTransformer model...\n",
      "✓ Embedding model loaded\n",
      "✓ Classifier loaded from models/classifier.pkl\n",
      "\n",
      "Model Configuration:\n",
      "  embedding_model: all-MiniLM-L6-v2\n",
      "  embedding_dimension: 384\n",
      "  classifier_type: LogisticRegression\n",
      "  training_samples: 210\n",
      "  validation_samples: 45\n",
      "  test_samples: 45\n",
      "  class_weight: balanced\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✓ Embedding model loaded\")\n",
    "\n",
    "# Load the trained classifier\n",
    "model_dir = Path('./models')\n",
    "classifier_path = model_dir / 'classifier.pkl'\n",
    "\n",
    "with open(classifier_path, 'rb') as f:\n",
    "    classifier = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Classifier loaded from {classifier_path}\")\n",
    "\n",
    "# Load configuration\n",
    "config_path = model_dir / 'config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Inference function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_relevance(abstract, title=None, verbose=True):\n",
    "    embedding = embedding_model.encode([abstract])\n",
    "    prediction = classifier.predict(embedding)[0]\n",
    "    probability = classifier.predict_proba(embedding)[0]\n",
    "    confidence = probability[prediction]\n",
    "    \n",
    "    result = {\n",
    "        'prediction': int(prediction),\n",
    "        'relevance_label': 'Relevant' if prediction == 1 else 'Not Relevant',\n",
    "        'confidence': float(confidence),\n",
    "        'probability_not_relevant': float(probability[0]),\n",
    "        'probability_relevant': float(probability[1])\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        if title:\n",
    "            print(f\"Title: {title}\")\n",
    "            print(\"-\"*70)\n",
    "        print(f\"Abstract (first 300 chars): {abstract[:300]}...\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Prediction: {result['relevance_label']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "        print(f\"  - P(Not Relevant): {result['probability_not_relevant']:.4f}\")\n",
    "        print(f\"  - P(Relevant): {result['probability_relevant']:.4f}\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"✓ Inference function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sample Data from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 300 samples from dataset\n",
      "\n",
      "Dataset composition:\n",
      "  Relevant papers: 53\n",
      "  Not relevant papers: 247\n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "data_path = Path('./data/data.json')\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"✓ Loaded {len(data)} samples from dataset\")\n",
    "\n",
    "# Find examples\n",
    "relevant_papers = [item for item in data if item['relevance'] == 1]\n",
    "not_relevant_papers = [item for item in data if item['relevance'] == 0]\n",
    "\n",
    "print(f\"\\nDataset composition:\")\n",
    "print(f\"  Relevant papers: {len(relevant_papers)}\")\n",
    "print(f\"  Not relevant papers: {len(not_relevant_papers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference Examples\n",
    "\n",
    "### Example 1: Relevant Paper (from dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Title: Code Researcher: Deep Research Agent for Large Systems Code and Commit History\n",
      "----------------------------------------------------------------------\n",
      "Abstract (first 300 chars): Large Language Model (LLM)-based coding agents have shown promising results on coding benchmarks, but their effectiveness on systems code remains underexplored. Due to the size and complexities of systems code, making changes to a systems codebase is a daunting task, even for humans. It requires res...\n",
      "======================================================================\n",
      "Prediction: Relevant\n",
      "Confidence: 0.6556\n",
      "  - P(Not Relevant): 0.3444\n",
      "  - P(Relevant): 0.6556\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 1: A paper relevant to NLP/AI research\n",
    "example1 = relevant_papers[0]\n",
    "\n",
    "result1 = predict_relevance(\n",
    "    abstract=example1['abstract'],\n",
    "    title=example1['title'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Not Relevant Paper (from dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Title: Chronoamperometry with Room-Temperature Ionic Liquids: Sub-Second Inference Techniques\n",
      "----------------------------------------------------------------------\n",
      "Abstract (first 300 chars): Chronoamperometry (CA) is a fundamental electrochemical technique used for quantifying redox-active species. However, in room-temperature ionic liquids (RTILs), the high viscosity and slow mass transport often lead to extended measurement durations. This paper presents a novel mathematical regressio...\n",
      "======================================================================\n",
      "Prediction: Not Relevant\n",
      "Confidence: 0.7688\n",
      "  - P(Not Relevant): 0.7688\n",
      "  - P(Relevant): 0.2312\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 2: A paper NOT relevant to research interests\n",
    "example2 = not_relevant_papers[0]\n",
    "\n",
    "result2 = predict_relevance(\n",
    "    abstract=example2['abstract'],\n",
    "    title=example2['title'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Another Relevant Paper (from dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Title: FusionAudio-1.2M: Towards Fine-grained Audio Captioning with Multimodal Contextual Fusion\n",
      "----------------------------------------------------------------------\n",
      "Abstract (first 300 chars): High-quality, large-scale audio captioning is crucial for advancing audio understanding, yet current automated methods often generate captions that lack fine-grained detail and contextual accuracy, primarily due to their reliance on limited unimodal or superficial multimodal information. Drawing ins...\n",
      "======================================================================\n",
      "Prediction: Relevant\n",
      "Confidence: 0.6629\n",
      "  - P(Not Relevant): 0.3371\n",
      "  - P(Relevant): 0.6629\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Another relevant paper\n",
    "example3 = relevant_papers[1] if len(relevant_papers) > 1 else relevant_papers[0]\n",
    "\n",
    "result3 = predict_relevance(\n",
    "    abstract=example3['abstract'],\n",
    "    title=example3['title'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Custom Abstract - NLP Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Title: Efficient Attention Mechanisms for Large Language Models\n",
      "----------------------------------------------------------------------\n",
      "Abstract (first 300 chars): This paper proposes a novel approach to improving language model efficiency by introducing a new attention mechanism that reduces computational complexity. We evaluate our method on standard benchmarks including GLUE and SQuAD, demonstrating consistent improvements over baselines. The proposed techn...\n",
      "======================================================================\n",
      "Prediction: Relevant\n",
      "Confidence: 0.6291\n",
      "  - P(Not Relevant): 0.3709\n",
      "  - P(Relevant): 0.6291\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Custom abstract about NLP and transformers\n",
    "custom_abstract_nlp = \"This paper proposes a novel approach to improving language model efficiency by introducing a new attention mechanism that reduces computational complexity. We evaluate our method on standard benchmarks including GLUE and SQuAD, demonstrating consistent improvements over baselines. The proposed technique can be easily integrated into existing transformer architectures.\"\n",
    "\n",
    "result4 = predict_relevance(\n",
    "    abstract=custom_abstract_nlp,\n",
    "    title=\"Efficient Attention Mechanisms for Large Language Models\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Custom Abstract - Different Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Title: Catalytic Properties of Transition Metal Complexes\n",
      "----------------------------------------------------------------------\n",
      "Abstract (first 300 chars): We investigate the catalytic properties of transition metal complexes in organic synthesis. Using X-ray crystallography and spectroscopic analysis, we characterize novel intermediates formed during the reaction mechanism. Our findings suggest new pathways for selective C-C bond formation in pharmace...\n",
      "======================================================================\n",
      "Prediction: Not Relevant\n",
      "Confidence: 0.8112\n",
      "  - P(Not Relevant): 0.8112\n",
      "  - P(Relevant): 0.1888\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 5: Custom abstract about chemistry (likely not relevant to ML research)\n",
    "custom_abstract_chem = \"We investigate the catalytic properties of transition metal complexes in organic synthesis. Using X-ray crystallography and spectroscopic analysis, we characterize novel intermediates formed during the reaction mechanism. Our findings suggest new pathways for selective C-C bond formation in pharmaceutical applications.\"\n",
    "\n",
    "result5 = predict_relevance(\n",
    "    abstract=custom_abstract_chem,\n",
    "    title=\"Catalytic Properties of Transition Metal Complexes\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Inference on First 10 Papers from Dataset:\n",
      "======================================================================\n",
      " index                                                 title   prediction confidence       actual  correct\n",
      "     0 Chronoamperometry with Room-Temperature Ionic Liqu... Not Relevant     0.7688 Not Relevant     True\n",
      "     1 Code Researcher: Deep Research Agent for Large Sys...     Relevant     0.6556     Relevant     True\n",
      "     2 FusionAudio-1.2M: Towards Fine-grained Audio Capti...     Relevant     0.6629     Relevant     True\n",
      "     3 Prithvi-EO-2.0: A Versatile Multi-Temporal Foundat... Not Relevant     0.7529 Not Relevant     True\n",
      "     4 Exploiting Dialect Identification in Automatic Dia...     Relevant     0.5785 Not Relevant    False\n",
      "     5 SPICED: Syntactical Bug and Trojan Pattern Identif... Not Relevant     0.6219 Not Relevant     True\n",
      "     6 On the Effectiveness of LLMs for Manual Test Verif...     Relevant     0.7039 Not Relevant    False\n",
      "     7            Efficient Curvature-aware Graph Network... Not Relevant     0.9025 Not Relevant     True\n",
      "     8 DAM-Seg: Anatomically accurate cardiac segmentatio... Not Relevant     0.8399 Not Relevant     True\n",
      "     9 JacNet: Learning Functions with Structured Jacobia... Not Relevant     0.8919 Not Relevant     True\n",
      "\n",
      "Batch Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "# Perform batch inference on the first 10 papers\n",
    "print(\"\\nBatch Inference on First 10 Papers from Dataset:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "batch_results = []\n",
    "for i, paper in enumerate(data[:10]):\n",
    "    result = predict_relevance(\n",
    "        abstract=paper['abstract'],\n",
    "        title=paper['title'],\n",
    "        verbose=False\n",
    "    )\n",
    "    batch_results.append({\n",
    "        'index': i,\n",
    "        'title': paper['title'][:50] + '...',\n",
    "        'prediction': result['relevance_label'],\n",
    "        'confidence': f\"{result['confidence']:.4f}\",\n",
    "        'actual': 'Relevant' if paper['relevance'] == 1 else 'Not Relevant',\n",
    "        'correct': (result['prediction'] == paper['relevance'])\n",
    "    })\n",
    "\n",
    "# Print batch results\n",
    "batch_df = pd.DataFrame(batch_results)\n",
    "print(batch_df.to_string(index=False))\n",
    "\n",
    "# Calculate accuracy on this batch\n",
    "batch_accuracy = batch_df['correct'].sum() / len(batch_df)\n",
    "print(f\"\\nBatch Accuracy: {batch_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INFERENCE RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Example 1 - Relevant Paper:\n",
      "  Prediction: Relevant (confidence: 0.6556)\n",
      "\n",
      "Example 2 - Not Relevant Paper:\n",
      "  Prediction: Not Relevant (confidence: 0.7688)\n",
      "\n",
      "Example 3 - Another Relevant Paper:\n",
      "  Prediction: Relevant (confidence: 0.6629)\n",
      "\n",
      "Example 4 - Custom NLP Abstract:\n",
      "  Prediction: Relevant (confidence: 0.6291)\n",
      "\n",
      "Example 5 - Custom Chemistry Abstract:\n",
      "  Prediction: Not Relevant (confidence: 0.8112)\n",
      "\n",
      "Batch Results (First 10 Papers):\n",
      "  Batch Accuracy: 80.00%\n",
      "\n",
      "======================================================================\n",
      "Model successfully demonstrates inference capabilities!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFERENCE RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nExample 1 - Relevant Paper:\")\n",
    "print(f\"  Prediction: {result1['relevance_label']} (confidence: {result1['confidence']:.4f})\")\n",
    "\n",
    "print(f\"\\nExample 2 - Not Relevant Paper:\")\n",
    "print(f\"  Prediction: {result2['relevance_label']} (confidence: {result2['confidence']:.4f})\")\n",
    "\n",
    "print(f\"\\nExample 3 - Another Relevant Paper:\")\n",
    "print(f\"  Prediction: {result3['relevance_label']} (confidence: {result3['confidence']:.4f})\")\n",
    "\n",
    "print(f\"\\nExample 4 - Custom NLP Abstract:\")\n",
    "print(f\"  Prediction: {result4['relevance_label']} (confidence: {result4['confidence']:.4f})\")\n",
    "\n",
    "print(f\"\\nExample 5 - Custom Chemistry Abstract:\")\n",
    "print(f\"  Prediction: {result5['relevance_label']} (confidence: {result5['confidence']:.4f})\")\n",
    "\n",
    "print(f\"\\nBatch Results (First 10 Papers):\")\n",
    "print(f\"  Batch Accuracy: {batch_accuracy:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Model successfully demonstrates inference capabilities!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
